{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Install dependencies",
   "id": "6e1a58e5b8184e81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:17:11.801062Z",
     "start_time": "2025-05-28T01:17:10.403854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from google.adk.tools import ToolContext\n",
    "%pip install --upgrade --quite 'google-adk'\n",
    "%pip install --upgrade --quite 'google-cloud-aiplatform[evaluation]'\n",
    "\n",
    "%pip install python-dotenv\n",
    "%pip install plotly"
   ],
   "id": "115fd70be4d376dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Usage:   \r\n",
      "  /Users/lingyimu/Projects/mock-interview-bot/.venv/bin/python -m pip install [options] <requirement specifier> [package-index-options] ...\r\n",
      "  /Users/lingyimu/Projects/mock-interview-bot/.venv/bin/python -m pip install [options] -r <requirements file> [package-index-options] ...\r\n",
      "  /Users/lingyimu/Projects/mock-interview-bot/.venv/bin/python -m pip install [options] [-e] <vcs project url> ...\r\n",
      "  /Users/lingyimu/Projects/mock-interview-bot/.venv/bin/python -m pip install [options] [-e] <local project path> ...\r\n",
      "  /Users/lingyimu/Projects/mock-interview-bot/.venv/bin/python -m pip install [options] <archive url/path> ...\r\n",
      "\r\n",
      "no such option: --quite\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\r\n",
      "Usage:   \r\n",
      "  /Users/lingyimu/Projects/mock-interview-bot/.venv/bin/python -m pip install [options] <requirement specifier> [package-index-options] ...\r\n",
      "  /Users/lingyimu/Projects/mock-interview-bot/.venv/bin/python -m pip install [options] -r <requirements file> [package-index-options] ...\r\n",
      "  /Users/lingyimu/Projects/mock-interview-bot/.venv/bin/python -m pip install [options] [-e] <vcs project url> ...\r\n",
      "  /Users/lingyimu/Projects/mock-interview-bot/.venv/bin/python -m pip install [options] [-e] <local project path> ...\r\n",
      "  /Users/lingyimu/Projects/mock-interview-bot/.venv/bin/python -m pip install [options] <archive url/path> ...\r\n",
      "\r\n",
      "no such option: --quite\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in /Users/lingyimu/Projects/mock-interview-bot/.venv/lib/python3.13/site-packages (1.1.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: plotly in /Users/lingyimu/Projects/mock-interview-bot/.venv/lib/python3.13/site-packages (6.0.1)\r\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Users/lingyimu/Projects/mock-interview-bot/.venv/lib/python3.13/site-packages (from plotly) (1.39.0)\r\n",
      "Requirement already satisfied: packaging in /Users/lingyimu/Projects/mock-interview-bot/.venv/lib/python3.13/site-packages (from plotly) (25.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### GCloud project info setup",
   "id": "7ff1ac4116744009"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:17:12.970232Z",
     "start_time": "2025-05-28T01:17:11.812792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import vertexai\n",
    "\n",
    "# directly read from .env\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "PROJECT_ID = os.environ[\"GOOGLE_CLOUD_PROJECT\"]\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_LOCATION\")\n",
    "BUCKET_URI=f\"gs://{os.environ.get(\"BUCKET_NAME\")}\"\n",
    "\n",
    "# set .env by default\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"True\"\n",
    "\n",
    "EXPERIMENT_NAME=\"evaluate-mock-interview-agent\"\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION, experiment=EXPERIMENT_NAME)\n",
    "\n",
    "assert PROJECT_ID\n",
    "assert LOCATION\n",
    "assert BUCKET_URI"
   ],
   "id": "81e8f419cd699dd1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-b2570076-5b55-4ca1-9fc7-fbd2eacc7ffa\" href=\"#view-view-vertex-resource-b2570076-5b55-4ca1-9fc7-fbd2eacc7ffa\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-b2570076-5b55-4ca1-9fc7-fbd2eacc7ffa');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-east1/experiments/evaluate-mock-interview-agent/runs?project=inspiring-radar-459602-i6');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-east1/experiments/evaluate-mock-interview-agent/runs?project=inspiring-radar-459602-i6', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports",
   "id": "bf81293c47d76efd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:17:12.997837Z",
     "start_time": "2025-05-28T01:17:12.994439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "# General\n",
    "import random\n",
    "import string\n",
    "from typing import Any\n",
    "\n",
    "from IPython.display import HTML, Markdown, display\n",
    "from google.adk.agents import Agent\n",
    "\n",
    "# Build agent with adk\n",
    "from google.adk.events import Event\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.tools import ToolContext, transfer_to_agent\n",
    "\n",
    "# Evaluate agent\n",
    "from google.cloud import aiplatform\n",
    "from google.genai import types\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from vertexai.preview.evaluation import EvalTask\n",
    "from vertexai.preview.evaluation.metrics import (\n",
    "    PointwiseMetric,\n",
    "    PointwiseMetricPromptTemplate,\n",
    "    TrajectorySingleToolUse,\n",
    ")"
   ],
   "id": "6ce946328bad42a",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Helper functions",
   "id": "c0a981dce410fa7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:17:13.020293Z",
     "start_time": "2025-05-28T01:17:13.009716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_id(length: int = 8) -> str:\n",
    "    \"\"\"Generate a uuid of a specified length (default=8).\"\"\"\n",
    "    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "\n",
    "def parse_adk_output_to_dictionary(events: list[Event]) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parse ADK event output into a structured dictionary format,\n",
    "    with the predicted trajectory dumped as a JSON string.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    final_response = \"\"\n",
    "    predicted_trajectory_list = []\n",
    "\n",
    "    for event in events:\n",
    "        # Ensure content and parts exist before accessing them\n",
    "        if not event.content or not event.content.parts:\n",
    "            continue\n",
    "\n",
    "        # Iterate through ALL parts in the event's content\n",
    "        for part in event.content.parts:\n",
    "            if part.function_call:\n",
    "                tool_info = {\n",
    "                    \"tool_name\": part.function_call.name,\n",
    "                    \"tool_input\": dict(part.function_call.args),\n",
    "                }\n",
    "                # Ensure we don't add duplicates if the same call appears somehow\n",
    "                if tool_info not in predicted_trajectory_list:\n",
    "                    predicted_trajectory_list.append(tool_info)\n",
    "\n",
    "            # The final text response is usually in the last event from the model\n",
    "            if event.content.role == \"model\" and part.text:\n",
    "                # Overwrite response; the last text response found is likely the final one\n",
    "                final_response = part.text.strip()\n",
    "\n",
    "    # Dump the collected trajectory list into a JSON string\n",
    "    final_output = {\n",
    "        \"response\": str(final_response),\n",
    "        \"predicted_trajectory\": json.dumps(predicted_trajectory_list),\n",
    "    }\n",
    "\n",
    "    return final_output\n",
    "\n",
    "\n",
    "def format_output_as_markdown(output: dict) -> str:\n",
    "    \"\"\"Convert the output dictionary to a formatted markdown string.\"\"\"\n",
    "    markdown = \"### AI Response\\n\"\n",
    "    markdown += f\"{output['response']}\\n\\n\"\n",
    "\n",
    "    if output[\"predicted_trajectory\"]:\n",
    "        output[\"predicted_trajectory\"] = json.loads(output[\"predicted_trajectory\"])\n",
    "        markdown += \"### Function Calls\\n\"\n",
    "        for call in output[\"predicted_trajectory\"]:\n",
    "            markdown += f\"- **Function**: `{call['tool_name']}`\\n\"\n",
    "            markdown += \"  - **Arguments**:\\n\"\n",
    "            for key, value in call[\"tool_input\"].items():\n",
    "                markdown += f\"    - `{key}`: `{value}`\\n\"\n",
    "\n",
    "    return markdown\n",
    "\n",
    "\n",
    "def display_eval_report(eval_result: pd.DataFrame) -> None:\n",
    "    \"\"\"Display the evaluation results.\"\"\"\n",
    "    metrics_df = pd.DataFrame.from_dict(eval_result.summary_metrics, orient=\"index\").T\n",
    "    display(Markdown(\"### Summary Metrics\"))\n",
    "    display(metrics_df)\n",
    "\n",
    "    display(Markdown(\"### Row-wise Metrics\"))\n",
    "    display(eval_result.metrics_table)\n",
    "\n",
    "\n",
    "def display_drilldown(row: pd.Series) -> None:\n",
    "    \"\"\"Displays a drill-down view for trajectory data within a row.\"\"\"\n",
    "\n",
    "    style = \"white-space: pre-wrap; width: 800px; overflow-x: auto;\"\n",
    "\n",
    "    if not (\n",
    "        isinstance(row[\"predicted_trajectory\"], list)\n",
    "        and isinstance(row[\"reference_trajectory\"], list)\n",
    "    ):\n",
    "        return\n",
    "\n",
    "    for predicted_trajectory, reference_trajectory in zip(\n",
    "        row[\"predicted_trajectory\"], row[\"reference_trajectory\"]\n",
    "    ):\n",
    "        display(\n",
    "            HTML(\n",
    "                f\"<h3>Tool Names:</h3><div style='{style}'>{predicted_trajectory['tool_name'], reference_trajectory['tool_name']}</div>\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if not (\n",
    "            isinstance(predicted_trajectory.get(\"tool_input\"), dict)\n",
    "            and isinstance(reference_trajectory.get(\"tool_input\"), dict)\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        for tool_input_key in predicted_trajectory[\"tool_input\"]:\n",
    "            print(\"Tool Input Key: \", tool_input_key)\n",
    "\n",
    "            if tool_input_key in reference_trajectory[\"tool_input\"]:\n",
    "                print(\n",
    "                    \"Tool Values: \",\n",
    "                    predicted_trajectory[\"tool_input\"][tool_input_key],\n",
    "                    reference_trajectory[\"tool_input\"][tool_input_key],\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    \"Tool Values: \",\n",
    "                    predicted_trajectory[\"tool_input\"][tool_input_key],\n",
    "                    \"N/A\",\n",
    "                )\n",
    "        print(\"\\n\")\n",
    "    display(HTML(\"<hr>\"))\n",
    "\n",
    "\n",
    "def display_dataframe_rows(\n",
    "    df: pd.DataFrame,\n",
    "    columns: list[str] | None = None,\n",
    "    num_rows: int = 3,\n",
    "    display_drilldown: bool = False,\n",
    ") -> None:\n",
    "    \"\"\"Displays a subset of rows from a DataFrame, optionally including a drill-down view.\"\"\"\n",
    "\n",
    "    if columns:\n",
    "        df = df[columns]\n",
    "\n",
    "    base_style = \"font-family: monospace; font-size: 14px; white-space: pre-wrap; width: auto; overflow-x: auto;\"\n",
    "    header_style = base_style + \"font-weight: bold;\"\n",
    "\n",
    "    for _, row in df.head(num_rows).iterrows():\n",
    "        for column in df.columns:\n",
    "            display(\n",
    "                HTML(\n",
    "                    f\"<span style='{header_style}'>{column.replace('_', ' ').title()}: </span>\"\n",
    "                )\n",
    "            )\n",
    "            display(HTML(f\"<span style='{base_style}'>{row[column]}</span><br>\"))\n",
    "\n",
    "        display(HTML(\"<hr>\"))\n",
    "\n",
    "        if (\n",
    "            display_drilldown\n",
    "            and \"predicted_trajectory\" in df.columns\n",
    "            and \"reference_trajectory\" in df.columns\n",
    "        ):\n",
    "            display_drilldown(row)\n",
    "\n",
    "\n",
    "def plot_bar_plot(\n",
    "    eval_result: pd.DataFrame, title: str, metrics: list[str] = None\n",
    ") -> None:\n",
    "    fig = go.Figure()\n",
    "    data = []\n",
    "\n",
    "    summary_metrics = eval_result.summary_metrics\n",
    "    if metrics:\n",
    "        summary_metrics = {\n",
    "            k: summary_metrics[k]\n",
    "            for k, v in summary_metrics.items()\n",
    "            if any(selected_metric in k for selected_metric in metrics)\n",
    "        }\n",
    "\n",
    "    data.append(\n",
    "        go.Bar(\n",
    "            x=list(summary_metrics.keys()),\n",
    "            y=list(summary_metrics.values()),\n",
    "            name=title,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data)\n",
    "\n",
    "    # Change the bar mode\n",
    "    fig.update_layout(barmode=\"group\")\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def display_radar_plot(eval_results, title: str, metrics=None):\n",
    "    \"\"\"Plot the radar plot.\"\"\"\n",
    "    fig = go.Figure()\n",
    "    summary_metrics = eval_results.summary_metrics\n",
    "    if metrics:\n",
    "        summary_metrics = {\n",
    "            k: summary_metrics[k]\n",
    "            for k, v in summary_metrics.items()\n",
    "            if any(selected_metric in k for selected_metric in metrics)\n",
    "        }\n",
    "\n",
    "    min_val = min(summary_metrics.values())\n",
    "    max_val = max(summary_metrics.values())\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatterpolar(\n",
    "            r=list(summary_metrics.values()),\n",
    "            theta=list(summary_metrics.keys()),\n",
    "            fill=\"toself\",\n",
    "            name=title,\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        polar=dict(radialaxis=dict(visible=True, range=[min_val, max_val])),\n",
    "        showlegend=True,\n",
    "    )\n",
    "    fig.show()"
   ],
   "id": "46834aeaff2ed8e5",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build agent problem-generator",
   "id": "4fe1794d25f4d9d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tools",
   "id": "c1cbcd652511d894"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:17:13.030324Z",
     "start_time": "2025-05-28T01:17:13.027687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def write_problem_to_session(problem_json: str, tool_context: ToolContext):\n",
    "    \"\"\"\n",
    "    Use this tool after generating the problem JSON.\n",
    "    Formats the problem into a dictionary and stores it in the session state\n",
    "    Args:\n",
    "        problem_json (str): The string representing the problem JSON.\n",
    "    \"\"\"\n",
    "    problem = json.loads(problem_json)\n",
    "    key_stem = \"temp:problem\"\n",
    "    for key, value in problem.items():\n",
    "        tool_context.state[f\"{key_stem}_{key}\"] = value\n",
    "    print(\"After update: \")\n",
    "    print(tool_context.state)\n",
    "    return {\"success\": True, \"problem\": problem}\n"
   ],
   "id": "e98c0de6761f157d",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The agent",
   "id": "99646786c5bf0f85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:24:35.849713Z",
     "start_time": "2025-05-28T01:24:35.845137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = \"gemini-2.0-flash\"\n",
    "\n",
    "\n",
    "def get_session(app_name, user_id, session_id):\n",
    "    session_service = InMemorySessionService()\n",
    "    session = session_service.create_session(\n",
    "        app_name=app_name, user_id=user_id, session_id=session_id)\n",
    "    return session_service, session\n",
    "\n",
    "\n",
    "def get_agent(query):\n",
    "    agent = Agent(\n",
    "        name=\"ProblemGenerator\",\n",
    "        model = model,\n",
    "        description = \"An agent that generates LeetCode-style coding questions.\",\n",
    "        instruction=f\"\"\"\n",
    "        Analyze this user request: '{query}'. Generate a Python dictionary describing a LeetCode-style coding question. After successful dict generation, use tool write_problem_to_session.\n",
    "\n",
    "        The dict should have these following keys:\n",
    "        \"description\": Generate a LeetCode-style coding question at the user's specified difficulty level in the user-specified topic if possible. Do NOT include any assumptions. Do NOT include text that's obviously a hint for any solution.\n",
    "        \"assumptions\": A list of assumptions that user can make about the problem.\n",
    "        \"valid_input\": Describe what is considered valid input for this question.\n",
    "        \"examples\": Give 1-3 simple examples of inputs and expected outputs.\n",
    "        \"constraints\": Optionally specify ideal time and space constraints.\n",
    "        \"input_size\": Describe sizes for any variables/inputs in the problem.\n",
    "        \"\"\",\n",
    "        tools=[write_problem_to_session]\n",
    "    )\n",
    "    return agent\n"
   ],
   "id": "dc3e6631df1a50d1",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test agent",
   "id": "c43774c3685e46a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:26:13.346326Z",
     "start_time": "2025-05-28T01:25:25.587729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "app_name = \"mock_interview_conductor\"\n",
    "user_id = \"user_one\"\n",
    "session_id = \"session_one\"\n",
    "\n",
    "query = \"Difficulty level: easy, topic: two-pointer\"\n",
    "\n",
    "session_service, session = get_session(app_name, user_id, session_id)\n",
    "agent = get_agent(query)\n",
    "\n",
    "runner = Runner(\n",
    "    agent=agent, app_name=app_name,\n",
    "    session_service=session_service\n",
    ")\n",
    "content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "events = list(\n",
    "    runner.run(user_id=user_id, session_id=session_id, new_message=content)\n",
    ")\n",
    "\n",
    "\n",
    "response = parse_adk_output_to_dictionary(events)\n",
    "display(Markdown(format_output_as_markdown(response)))"
   ],
   "id": "ab99e728fb2f6ed3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "### AI Response\n```json\n{\n  \"description\": \"Given a sorted array of integers, determine if there exist two numbers such that they add up to a specific target value. Return true if such a pair exists, and false otherwise.\",\n  \"assumptions\": [\n    \"The input array is sorted in ascending order.\",\n    \"The input array contains only integers.\"\n  ],\n  \"valid_input\": \"A sorted array of integers and an integer target value.\",\n  \"examples\": [\n    {\n      \"input\": {\n        \"array\": [2, 7, 11, 15],\n        \"target\": 9\n      },\n      \"output\": true\n    },\n    {\n      \"input\": {\n        \"array\": [2, 7, 11, 15],\n        \"target\": 10\n      },\n      \"output\": true\n    },\n    {\n      \"input\": {\n        \"array\": [2, 7, 11, 15],\n        \"target\": 5\n      },\n      \"output\": false\n    }\n  ],\n  \"constraints\": \"Time complexity: O(n), Space complexity: O(1)\",\n  \"input_size\": \"The array can contain up to 10^4 elements. The target value can be any integer.\"\n}\n```\n\n### Function Calls\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c903f0a910c2ae72"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluate agent\n",
    "The tool `write_problem_to_session` should always be called."
   ],
   "id": "714c772cb9334c90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T01:17:15.653074Z",
     "start_time": "2025-05-28T01:17:15.650256Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "278ce243b631891",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
